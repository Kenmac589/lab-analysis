{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "887d7e3a",
   "metadata": {},
   "source": [
    "# This is the analysis for Center of Mass Project\n",
    "\n",
    "The goal of this is notebook is to bring together the general guidance on using DeepLabCut, while making the analysis executable in context with the associated directions. The first step will be to activate the relevant `conda` environment, which contains DeepLabCut. \n",
    "- In the case of the GPU computer, this will be done by launching the *anaconda prompt (anaconda powershell prompt is also fine)* in administator mode and typing `conda activate dlc-windowsGPU-2023'` \n",
    "- If you are using you're own PC, then the command would be `conda activate DEEPLABCUT`.\n",
    "\n",
    "\n",
    "\n",
    "## General Overview\n",
    "\n",
    "1. Import relevant packages and create project\n",
    "2. Extract frames from imported videos\n",
    "3. Label frames from videos to denote anatomincal landmarks\n",
    "4. Train Neural Network (GPU Intensive)\n",
    "5. Evalualte Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8489d94f",
   "metadata": {},
   "source": [
    "First step will be to import deeplabcut.\n",
    "- Running blocks of code in jupyter is done by making sure that you are one the block you want to run and either pressing the run button above or the shortcut (Ctrl+Enter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74474261",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.5...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de7f2e22",
   "metadata": {},
   "source": [
    "*Keeping Track of included Videos for Age Cont*\n",
    "\n",
    "***M1 (7-3-9, 246)***\n",
    "\n",
    "- ACnE_M1_20230711_000000: 0.100 non-per\n",
    "- ACnE_M1_20230711_000001: 0.100 non-per\n",
    "- ACnE_M1_20230711_000006: 0.100 per\n",
    "- ACnE_M1_20230711_000009: 0.100 sin\n",
    "\n",
    "***M2 (7-3-11, 248)***\n",
    "\n",
    "- ACnE_M2_20230712_000000: 0.100 non-per\n",
    "- ACnE_M2_20230712_000004: 0.100 per\n",
    "- ACnE_M2_20230712_000007: 0.100 sin\n",
    "\n",
    "***(7-3-10, 247)***\n",
    "\n",
    "- ACnE_M3_20230713_000000: 0.100 non-per\n",
    "- ACnE_M3_20230713_000003: 0.100 per\n",
    "- ACnE_M3_20230713_000006: 0.100 sin\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a5c98c",
   "metadata": {},
   "source": [
    "### Project Creation\n",
    "\n",
    "Here we will use the block written below to create a new project.\n",
    "\n",
    "> Do not run the block below if you have already made your project. You can move down to the block containing `config_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd12d43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Name: ACnE-selections\n",
      "Experimenter: kenzie\n",
      "Output of file paths:\n",
      "--------------------\n",
      "['/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M1_20230711_000000.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M1_20230711_000001.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M1_20230711_000006.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M1_20230711_000009.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M2_20230712_000000.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M2_20230712_000004.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M2_20230712_000007.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M3_20230713_000000.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M3_20230713_000003.avi', '/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/ACnE_M3_20230713_000006.avi']\n",
      "Directory ACnE-selections-kenzie-2023-07-14 does not exist in /home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/.\n",
      "Created \"/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos\"\n",
      "Created \"/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data\"\n",
      "Created \"/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/training-datasets\"\n",
      "Created \"/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/dlc-models\"\n",
      "Copying the videos\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M1_20230711_000000.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M1_20230711_000001.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M1_20230711_000006.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M1_20230711_000009.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M2_20230712_000000.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M2_20230712_000004.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M2_20230712_000007.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M3_20230713_000000.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M3_20230713_000003.avi\n",
      "/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/videos/ACnE_M3_20230713_000006.avi\n",
      "Generated \"/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/config.yaml\"\n",
      "\n",
      "A new project with name ACnE-selections-kenzie-2023-07-14 is created at /home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb  6 11:09:35 2023\n",
    "\n",
    "@author: Kenzie MacKinnon\n",
    "\n",
    "The purpose of this script is to facilitate the import and creation of a new\n",
    "DeepLabCut project.\n",
    "\n",
    "The does project creation in a more interactive way if you run it.\n",
    "You can also assign the appropriate variable in the code block below\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# %% Imports\n",
    "import os\n",
    "import platform\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Functions\n",
    "def filePathList(dir_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "def pathconvUnixToDos(paths):\n",
    "    dos_paths = []\n",
    "    for path in paths:\n",
    "        dos_path = path.replace('/', '\\\\')\n",
    "        dos_paths.append(dos_path)\n",
    "    return dos_paths\n",
    "\n",
    "def directoryPresent(targetPath, projName):\n",
    "    path = os.path.join(projName, targetPath)\n",
    "\n",
    "    # Will return boolean\n",
    "    return os.path.isdir(path)\n",
    "\n",
    "# Gathering User input\n",
    "projectName = \"ACnE-selections\"\n",
    "experimenterName = \"kenzie\"\n",
    "targetForProject = \"/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/\"\n",
    "videoImportPath = \"/home/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/selected_videos/\"\n",
    "\n",
    "file_paths = filePathList(videoImportPath)\n",
    "\n",
    "# Checking result of variable file path importing\n",
    "print(\"Project Name: \" + projectName)\n",
    "print(\"Experimenter: \" + experimenterName)\n",
    "print(\"Output of file paths:\")\n",
    "print(\"--------------------\")\n",
    "print(file_paths)\n",
    "# %% Creation of project\n",
    "\n",
    "# Checking to see if project with same name already exists\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "newProjectName = projectName + \"-\" + experimenterName + \"-\" + current_date\n",
    "\n",
    "if directoryPresent(newProjectName, targetForProject):\n",
    "    print(f\"Directory {newProjectName} already exists in {targetForProject}.\")\n",
    "else:\n",
    "    print(f\"Directory {newProjectName} does not exist in {targetForProject}.\")\n",
    "    config_path = deeplabcut.create_new_project(projectName, experimenterName, file_paths, working_directory=(targetForProject), copy_videos=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d98cdf44",
   "metadata": {},
   "source": [
    "On windows server config path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce5c7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_path = 'C:\\\\Users\\\\GPU\\\\Documents\\\\DeepLabCut\\\\temp_kenzie\\\\CoM\\\\DTR\\\\DTR-pre-kenzie-2023-07-06\\\\config.yaml'\n",
    "videofile_path = '\\\\Kenzie\\\\CoM\\\\DTR\\\\DTR-M5\\\\DTR-M5-20230404_pre-DTX\\\\'\n",
    "VideoType = 'avi'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa2a363a",
   "metadata": {},
   "source": [
    "On unix server config path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ede3c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_path = \"/Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7d45b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 5.91  seconds.\n",
      "Extracting and downsampling... 2956  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2956it [00:33, 88.15it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 4.72  seconds.\n",
      "Extracting and downsampling... 2359  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2359it [00:28, 82.28it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 3.96  seconds.\n",
      "Extracting and downsampling... 1980  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1980it [00:23, 85.50it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 3.35  seconds.\n",
      "Extracting and downsampling... 1676  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1676it [00:19, 88.02it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 5.42  seconds.\n",
      "Extracting and downsampling... 2710  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2710it [00:29, 91.86it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 3.46  seconds.\n",
      "Extracting and downsampling... 1731  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1731it [00:18, 94.46it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 2.08  seconds.\n",
      "Extracting and downsampling... 1038  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1038it [00:11, 92.94it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 3.34  seconds.\n",
      "Extracting and downsampling... 1668  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1668it [00:17, 93.05it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 7.81  seconds.\n",
      "Extracting and downsampling... 3904  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3904it [00:48, 80.52it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 5.19  seconds.\n",
      "Extracting and downsampling... 2593  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2593it [00:35, 72.66it/s]\n",
      "/home/kenzie_mackinnon/miniforge/envs/dlc/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(config_path, mode='automatic', algo='kmeans', userfeedback=False, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34fbf19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: could not determine DPI\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef14d71c",
   "metadata": {},
   "source": [
    "### Checking Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100c27f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by kenzie.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.28it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention: /Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M1_20230711_000006 does not appear to have labeled data!\n",
      "Attention: /Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M1_20230711_000009 does not appear to have labeled data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.47it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention: /Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M2_20230712_000007 does not appear to have labeled data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention: /Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M3_20230713_000003 does not appear to have labeled data!\n",
      "Attention: /Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M3_20230713_000006 does not appear to have labeled data!\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path, visualizeindividuals=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a82e04ff",
   "metadata": {},
   "source": [
    "### Create Training Dataset\n",
    "\n",
    "Only run this step where you are going to train the network. If you label on your laptop but move your project folder to Google Colab or AWS, lab server, etc, then run the step below on that platform! If you labeled on a Windows machine but train on Linux, this is fine as of 2.0.4 onwards it will be done automatically (it saves file sets as both Linux and Windows for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d2260e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M1_20230711_000006/CollectedData_kenzie.h5  not found (perhaps not annotated).\n",
      "/Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M1_20230711_000009/CollectedData_kenzie.h5  not found (perhaps not annotated).\n",
      "/Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M2_20230712_000007/CollectedData_kenzie.h5  not found (perhaps not annotated).\n",
      "/Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M3_20230713_000003/CollectedData_kenzie.h5  not found (perhaps not annotated).\n",
      "/Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/labeled-data/ACnE_M3_20230713_000006/CollectedData_kenzie.h5  not found (perhaps not annotated).\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([42, 96, 58, 14, 72,  4, 47, 64, 57, 63,  6, 38, 13, 59, 66, 71, 15,\n",
       "          22, 19, 12, 52, 73, 80, 74, 62, 30, 99, 70, 18, 89, 81, 83, 60, 25,\n",
       "          56, 17,  1,  8, 16, 55, 48, 92,  0, 36, 40,  5, 94, 98, 49, 34, 91,\n",
       "          33, 21, 90,  7, 45, 79, 85, 68, 31, 65, 44, 50, 26, 75, 95, 78, 41,\n",
       "           9, 39, 93, 97, 29, 77, 20, 46, 51, 53, 23, 27,  2, 28, 37, 54, 10,\n",
       "          84, 11, 32, 43, 87, 69, 61, 86, 35, 76]),\n",
       "   array([ 3, 82, 67, 24, 88])))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path, augmenter_type='imgaug')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a1d9aad",
   "metadata": {},
   "source": [
    "### Network Training\n",
    "\n",
    "This part is where you would want to be leveraging the GPU's on the big PC to training the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41fb3a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18]],\n",
      " 'all_joints_names': ['calib_1',\n",
      "                      'calib_2',\n",
      "                      'calib_3',\n",
      "                      'calib_4',\n",
      "                      'calib_5',\n",
      "                      'calib_6',\n",
      "                      'iliac_crest',\n",
      "                      'hip',\n",
      "                      'knee',\n",
      "                      'ankle',\n",
      "                      'metatarsal',\n",
      "                      'toe',\n",
      "                      'fl_toe',\n",
      "                      'mirror_lhl',\n",
      "                      'mirror_rhl',\n",
      "                      'mirror_lfl',\n",
      "                      'mirror_rfl',\n",
      "                      'mirror_com',\n",
      "                      'mirror'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ACnE-selectionsJul14/ACnE-selections_kenzie95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/Users/kenzie_mackinnon/miniconda/envs/dlc/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ACnE-selectionsJul14/Documentation_data-ACnE-selections_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 19,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/Users//kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/Users/kenzie_mackinnon/sync/temp_kenzie/ACnE_selections/ACnE-selections-kenzie-2023-07-14/dlc-models/iteration-0/ACnE-selectionsJul14-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dtensor_api' from 'keras.dtensor' (/Users/kenzie_mackinnon/miniconda/envs/dlc/lib/python3.8/site-packages/keras/dtensor/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deeplabcut\u001b[39m.\u001b[39;49mtrain_network(config_path)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/training.py:223\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    212\u001b[0m         train(\n\u001b[1;32m    213\u001b[0m             \u001b[39mstr\u001b[39m(poseconfigfile),\n\u001b[1;32m    214\u001b[0m             displayiters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m             allow_growth\u001b[39m=\u001b[39mallow_growth,\n\u001b[1;32m    220\u001b[0m         )  \u001b[39m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    224\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     os\u001b[39m.\u001b[39mchdir(\u001b[39mstr\u001b[39m(start_path))\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/training.py:212\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mdeeplabcut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpose_estimation_tensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[1;32m    211\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSelecting single-animal trainer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 212\u001b[0m         train(\n\u001b[1;32m    213\u001b[0m             \u001b[39mstr\u001b[39;49m(poseconfigfile),\n\u001b[1;32m    214\u001b[0m             displayiters,\n\u001b[1;32m    215\u001b[0m             saveiters,\n\u001b[1;32m    216\u001b[0m             maxiters,\n\u001b[1;32m    217\u001b[0m             max_to_keep\u001b[39m=\u001b[39;49mmax_snapshots_to_keep,\n\u001b[1;32m    218\u001b[0m             keepdeconvweights\u001b[39m=\u001b[39;49mkeepdeconvweights,\n\u001b[1;32m    219\u001b[0m             allow_growth\u001b[39m=\u001b[39;49mallow_growth,\n\u001b[1;32m    220\u001b[0m         )  \u001b[39m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py:173\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    170\u001b[0m batch_spec \u001b[39m=\u001b[39m get_batch_spec(cfg)\n\u001b[1;32m    171\u001b[0m batch, enqueue_op, placeholders \u001b[39m=\u001b[39m setup_preloading(batch_spec)\n\u001b[0;32m--> 173\u001b[0m losses \u001b[39m=\u001b[39m PoseNetFactory\u001b[39m.\u001b[39;49mcreate(cfg)\u001b[39m.\u001b[39;49mtrain(batch)\n\u001b[1;32m    174\u001b[0m total_loss \u001b[39m=\u001b[39m losses[\u001b[39m\"\u001b[39m\u001b[39mtotal_loss\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    176\u001b[0m \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m losses\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/nnets/base.py:32\u001b[0m, in \u001b[0;36mBasePoseNet.train\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m---> 32\u001b[0m     heads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_net(batch[Batch\u001b[39m.\u001b[39;49minputs])\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg[\u001b[39m\"\u001b[39m\u001b[39mweigh_part_predictions\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     34\u001b[0m         part_score_weights \u001b[39m=\u001b[39m batch[Batch\u001b[39m.\u001b[39mpart_score_weights]\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py:79\u001b[0m, in \u001b[0;36mPoseResnet.get_net\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_net\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m---> 79\u001b[0m     net, end_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(inputs)\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_layers(net, end_points)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py:41\u001b[0m, in \u001b[0;36mPoseResnet.extract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     39\u001b[0m im_centered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcenter_inputs(inputs)\n\u001b[1;32m     40\u001b[0m \u001b[39mwith\u001b[39;00m slim\u001b[39m.\u001b[39marg_scope(resnet_v1\u001b[39m.\u001b[39mresnet_arg_scope()):\n\u001b[0;32m---> 41\u001b[0m     net, end_points \u001b[39m=\u001b[39m net_fun(\n\u001b[1;32m     42\u001b[0m         im_centered,\n\u001b[1;32m     43\u001b[0m         global_pool\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     44\u001b[0m         output_stride\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m     45\u001b[0m         is_training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m net, end_points\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/nets/resnet_v1.py:270\u001b[0m, in \u001b[0;36mresnet_v1_50\u001b[0;34m(inputs, num_classes, is_training, global_pool, output_stride, reuse, scope)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"ResNet-50 model of [1]. See resnet_v1() for arg and return description.\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m    265\u001b[0m     resnet_v1_block(\u001b[39m'\u001b[39m\u001b[39mblock1\u001b[39m\u001b[39m'\u001b[39m, base_depth\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, num_units\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m),\n\u001b[1;32m    266\u001b[0m     resnet_v1_block(\u001b[39m'\u001b[39m\u001b[39mblock2\u001b[39m\u001b[39m'\u001b[39m, base_depth\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, num_units\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m),\n\u001b[1;32m    267\u001b[0m     resnet_v1_block(\u001b[39m'\u001b[39m\u001b[39mblock3\u001b[39m\u001b[39m'\u001b[39m, base_depth\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, num_units\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m),\n\u001b[1;32m    268\u001b[0m     resnet_v1_block(\u001b[39m'\u001b[39m\u001b[39mblock4\u001b[39m\u001b[39m'\u001b[39m, base_depth\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, num_units\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    269\u001b[0m ]\n\u001b[0;32m--> 270\u001b[0m \u001b[39mreturn\u001b[39;00m resnet_v1(\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     blocks,\n\u001b[1;32m    273\u001b[0m     num_classes,\n\u001b[1;32m    274\u001b[0m     is_training,\n\u001b[1;32m    275\u001b[0m     global_pool,\n\u001b[1;32m    276\u001b[0m     output_stride,\n\u001b[1;32m    277\u001b[0m     include_root_block\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    278\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    279\u001b[0m     scope\u001b[39m=\u001b[39;49mscope)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/nets/resnet_v1.py:210\u001b[0m, in \u001b[0;36mresnet_v1\u001b[0;34m(inputs, blocks, num_classes, is_training, global_pool, output_stride, include_root_block, reuse, scope)\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe output_stride needs to be a multiple of 4.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    209\u001b[0m     output_stride \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m--> 210\u001b[0m   net \u001b[39m=\u001b[39m resnet_utils\u001b[39m.\u001b[39;49mconv2d_same(net, \u001b[39m64\u001b[39;49m, \u001b[39m7\u001b[39;49m, stride\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, scope\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    211\u001b[0m   net \u001b[39m=\u001b[39m layers_lib\u001b[39m.\u001b[39mmax_pool2d(net, [\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m], stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, scope\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpool1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    212\u001b[0m net \u001b[39m=\u001b[39m resnet_utils\u001b[39m.\u001b[39mstack_blocks_dense(net, blocks, output_stride)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/nets/resnet_utils.py:143\u001b[0m, in \u001b[0;36mconv2d_same\u001b[0;34m(inputs, num_outputs, kernel_size, stride, rate, scope)\u001b[0m\n\u001b[1;32m    140\u001b[0m pad_end \u001b[39m=\u001b[39m pad_total \u001b[39m-\u001b[39m pad_beg\n\u001b[1;32m    141\u001b[0m inputs \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    142\u001b[0m     inputs, [[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], [pad_beg, pad_end], [pad_beg, pad_end], [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]])\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m layers_lib\u001b[39m.\u001b[39;49mconv2d(\n\u001b[1;32m    144\u001b[0m     inputs,\n\u001b[1;32m    145\u001b[0m     num_outputs,\n\u001b[1;32m    146\u001b[0m     kernel_size,\n\u001b[1;32m    147\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m    148\u001b[0m     rate\u001b[39m=\u001b[39;49mrate,\n\u001b[1;32m    149\u001b[0m     padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mVALID\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    150\u001b[0m     scope\u001b[39m=\u001b[39;49mscope)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/ops/arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   current_args \u001b[39m=\u001b[39m current_scope[key_func]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    183\u001b[0m   current_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcurrent_args)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/layers/layers.py:1171\u001b[0m, in \u001b[0;36mconvolution2d\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39m@add_arg_scope\u001b[39m\n\u001b[1;32m   1152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvolution2d\u001b[39m(inputs,\n\u001b[1;32m   1153\u001b[0m                   num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                   trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1170\u001b[0m                   scope\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1171\u001b[0m   \u001b[39mreturn\u001b[39;00m convolution(\n\u001b[1;32m   1172\u001b[0m       inputs,\n\u001b[1;32m   1173\u001b[0m       num_outputs,\n\u001b[1;32m   1174\u001b[0m       kernel_size,\n\u001b[1;32m   1175\u001b[0m       stride,\n\u001b[1;32m   1176\u001b[0m       padding,\n\u001b[1;32m   1177\u001b[0m       data_format,\n\u001b[1;32m   1178\u001b[0m       rate,\n\u001b[1;32m   1179\u001b[0m       activation_fn,\n\u001b[1;32m   1180\u001b[0m       normalizer_fn,\n\u001b[1;32m   1181\u001b[0m       normalizer_params,\n\u001b[1;32m   1182\u001b[0m       weights_initializer,\n\u001b[1;32m   1183\u001b[0m       weights_regularizer,\n\u001b[1;32m   1184\u001b[0m       biases_initializer,\n\u001b[1;32m   1185\u001b[0m       biases_regularizer,\n\u001b[1;32m   1186\u001b[0m       reuse,\n\u001b[1;32m   1187\u001b[0m       variables_collections,\n\u001b[1;32m   1188\u001b[0m       outputs_collections,\n\u001b[1;32m   1189\u001b[0m       trainable,\n\u001b[1;32m   1190\u001b[0m       scope,\n\u001b[1;32m   1191\u001b[0m       conv_dims\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/ops/arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   current_args \u001b[39m=\u001b[39m current_scope[key_func]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    183\u001b[0m   current_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcurrent_args)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/layers/layers.py:1098\u001b[0m, in \u001b[0;36mconvolution\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope, conv_dims)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[39mif\u001b[39;00m normalizer_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m   normalizer_params \u001b[39m=\u001b[39m normalizer_params \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m-> 1098\u001b[0m   outputs \u001b[39m=\u001b[39m normalizer_fn(outputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnormalizer_params)\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m activation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m   outputs \u001b[39m=\u001b[39m activation_fn(outputs)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/ops/arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   current_args \u001b[39m=\u001b[39m current_scope[key_func]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    183\u001b[0m   current_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcurrent_args)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tf_slim/layers/layers.py:663\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, param_regularizers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope, renorm, renorm_clipping, renorm_decay, adjustment)\u001b[0m\n\u001b[1;32m    661\u001b[0m beta_regularizer \u001b[39m=\u001b[39m param_regularizers\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mbeta\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    662\u001b[0m gamma_regularizer \u001b[39m=\u001b[39m param_regularizers\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 663\u001b[0m layer \u001b[39m=\u001b[39m normalization_layers\u001b[39m.\u001b[39;49mBatchNormalization(\n\u001b[1;32m    664\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m    665\u001b[0m     momentum\u001b[39m=\u001b[39mdecay,\n\u001b[1;32m    666\u001b[0m     epsilon\u001b[39m=\u001b[39mepsilon,\n\u001b[1;32m    667\u001b[0m     center\u001b[39m=\u001b[39mcenter,\n\u001b[1;32m    668\u001b[0m     scale\u001b[39m=\u001b[39mscale,\n\u001b[1;32m    669\u001b[0m     beta_initializer\u001b[39m=\u001b[39mbeta_initializer,\n\u001b[1;32m    670\u001b[0m     gamma_initializer\u001b[39m=\u001b[39mgamma_initializer,\n\u001b[1;32m    671\u001b[0m     moving_mean_initializer\u001b[39m=\u001b[39mmoving_mean_initializer,\n\u001b[1;32m    672\u001b[0m     moving_variance_initializer\u001b[39m=\u001b[39mmoving_variance_initializer,\n\u001b[1;32m    673\u001b[0m     beta_regularizer\u001b[39m=\u001b[39mbeta_regularizer,\n\u001b[1;32m    674\u001b[0m     gamma_regularizer\u001b[39m=\u001b[39mgamma_regularizer,\n\u001b[1;32m    675\u001b[0m     trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[1;32m    676\u001b[0m     renorm\u001b[39m=\u001b[39mrenorm,\n\u001b[1;32m    677\u001b[0m     renorm_clipping\u001b[39m=\u001b[39mrenorm_clipping,\n\u001b[1;32m    678\u001b[0m     renorm_momentum\u001b[39m=\u001b[39mrenorm_decay,\n\u001b[1;32m    679\u001b[0m     adjustment\u001b[39m=\u001b[39madjustment,\n\u001b[1;32m    680\u001b[0m     name\u001b[39m=\u001b[39msc\u001b[39m.\u001b[39mname,\n\u001b[1;32m    681\u001b[0m     _scope\u001b[39m=\u001b[39msc,\n\u001b[1;32m    682\u001b[0m     _reuse\u001b[39m=\u001b[39mreuse,\n\u001b[1;32m    683\u001b[0m     fused\u001b[39m=\u001b[39mfused)\n\u001b[1;32m    684\u001b[0m outputs \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mapply(inputs, training\u001b[39m=\u001b[39mis_training)\n\u001b[1;32m    686\u001b[0m \u001b[39m# Add variables to collections.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tensorflow/python/layers/normalization.py:30\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(name):\n\u001b[1;32m     29\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mBatchNormalization\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBatchNorm\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m normalization\u001b[39m.\u001b[39;49mBatchNormalization\n\u001b[1;32m     31\u001b[0m   \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mbatch_normalization\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbatch_norm\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m normalization\u001b[39m.\u001b[39mbatch_normalization\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:58\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[0;32m---> 58\u001b[0m   module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n\u001b[1;32m     59\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:843\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/keras/legacy_tf_layers/normalization.py:25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnormalization\u001b[39;00m \u001b[39mimport\u001b[39;00m batch_normalization_v1\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy_tf_layers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[1;32m     28\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization_v1.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Batch Normalization V1 layer.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnormalization\u001b[39;00m \u001b[39mimport\u001b[39;00m batch_normalization\n\u001b[1;32m     20\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m regularizers\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m InputSpec\n",
      "File \u001b[0;32m~/miniconda/envs/dlc/lib/python3.8/site-packages/keras/dtensor/utils.py:21\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m dtensor_api \u001b[39mas\u001b[39;00m dtensor\n\u001b[1;32m     23\u001b[0m \u001b[39m# All the variable names in the default keras layers. We will use those to map\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# against the args in the __init__ method to find corresponding layout args.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# See allow_layout() for more details.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m KERAS_VARIABLE_NAMES \u001b[39m=\u001b[39m [\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbeta\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrecurrent\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'dtensor_api' from 'keras.dtensor' (/Users/kenzie_mackinnon/miniconda/envs/dlc/lib/python3.8/site-packages/keras/dtensor/__init__.py)"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6626d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "# Network evaluation\n",
    "\n",
    "deeplabcut.evaluate_network(config_path, plotting=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0bfe90e",
   "metadata": {},
   "source": [
    "# Begin Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ba541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(config_path, videofile_path, videotype=VideoType)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2da0c256",
   "metadata": {},
   "source": [
    "# Plot the Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21bd85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.plot_trajectories(config_path,videofile_path, videotype=VideoType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d5708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path, videofile_path, videotype=VideoType)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81a0de76",
   "metadata": {},
   "source": [
    "# Finding frames with abnormal body part Distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2100824",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "max_dist = 100\n",
    "df = pd.read_hdf('path_to_your_labeled_data_file')\n",
    "bpt1 = df.xs('head', level='bodyparts', axis=1).to_numpy()\n",
    "bpt2 = df.xs('tail', level='bodyparts', axis=1).to_numpy()\n",
    "# We calculate the vectors from a point to the other\n",
    "# and group them per frame and per animal.\n",
    "try:\n",
    "    diff = (bpt1 - bpt2).reshape((len(df), -1, 2))\n",
    "except ValueError:\n",
    "    diff = (bpt1 - bpt2).reshape((len(df), -1, 3))\n",
    "dist = np.linalg.norm(diff, axis=2)\n",
    "mask = np.any(dist >= max_dist, axis=1)\n",
    "flagged_frames = df.iloc[mask].index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9565301901e75327fdc7fb6f564cf4ec01f7a567182f2fdf4865a4f02c22ee08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
