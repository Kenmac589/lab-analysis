2024-02-26 10:49:09 Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18]],
 'all_joints_names': ['calib_1',
                      'calib_2',
                      'calib_3',
                      'calib_4',
                      'calib_5',
                      'calib_6',
                      'iliac_crest',
                      'hip',
                      'knee',
                      'ankle',
                      'metatarsal',
                      'toe',
                      'fl_toe',
                      'mirror_lhl',
                      'mirror_rhl',
                      'mirror_lfl',
                      'mirror_rfl',
                      'mirror_com',
                      'mirror'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'contrast': {'clahe': True,
              'claheratio': 0.1,
              'histeq': True,
              'histeqratio': 0.1},
 'convolution': {'edge': False,
                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},
                 'embossratio': 0.1,
                 'sharpen': False,
                 'sharpenratio': 0.3},
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_1yrDTRnoRosa-postDTXFeb13\\1yrDTRnoRosa-postDTX_kenzie95shuffle1.mat',
 'dataset_type': 'imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\GPU\\Documents\\DeepLabCut\\temp_kenzie\\CoM\\DTR\\1yrDTRnoRosa-postDTX-kenzie-2024-02-13\\dlc-models\\iteration-0\\1yrDTRnoRosa-postDTXFeb13-trainset95shuffle1\\train\\snapshot-500000',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_1yrDTRnoRosa-postDTXFeb13\\Documentation_data-1yrDTRnoRosa-postDTX_95shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 19,
 'optimizer': 'sgd',
 'pairwise_huber_loss': False,
 'pairwise_predict': False,
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'project_path': 'C:/Users/GPU/Documents/DeepLabCut/temp_kenzie/CoM/DTR/1yrDTRnoRosa-postDTX-kenzie-2024-02-13',
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\GPU\\Documents\\DeepLabCut\\temp_kenzie\\CoM\\DTR\\1yrDTRnoRosa-postDTX-kenzie-2024-02-13\\dlc-models\\iteration-1\\1yrDTRnoRosa-postDTXFeb13-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2024-02-26 10:53:57 iteration: 501000 loss: 0.0024 lr: 0.005
2024-02-26 10:55:42 iteration: 502000 loss: 0.0023 lr: 0.005
2024-02-26 10:57:17 iteration: 503000 loss: 0.0023 lr: 0.005
2024-02-26 10:58:49 iteration: 504000 loss: 0.0023 lr: 0.005
2024-02-26 11:00:19 iteration: 505000 loss: 0.0022 lr: 0.005
2024-02-26 11:01:52 iteration: 506000 loss: 0.0022 lr: 0.005
2024-02-26 11:03:21 iteration: 507000 loss: 0.0021 lr: 0.005
2024-02-26 11:04:53 iteration: 508000 loss: 0.0021 lr: 0.005
2024-02-26 11:06:25 iteration: 509000 loss: 0.0021 lr: 0.005
2024-02-26 11:07:56 iteration: 510000 loss: 0.0021 lr: 0.005
2024-02-26 11:09:28 iteration: 511000 loss: 0.0022 lr: 0.02
2024-02-26 11:10:59 iteration: 512000 loss: 0.0022 lr: 0.02
2024-02-26 11:12:30 iteration: 513000 loss: 0.0020 lr: 0.02
2024-02-26 11:14:02 iteration: 514000 loss: 0.0020 lr: 0.02
2024-02-26 11:15:33 iteration: 515000 loss: 0.0020 lr: 0.02
2024-02-26 11:17:05 iteration: 516000 loss: 0.0020 lr: 0.02
2024-02-26 11:18:36 iteration: 517000 loss: 0.0020 lr: 0.02
2024-02-26 11:20:06 iteration: 518000 loss: 0.0020 lr: 0.02
2024-02-26 11:21:39 iteration: 519000 loss: 0.0019 lr: 0.02
2024-02-26 11:23:13 iteration: 520000 loss: 0.0020 lr: 0.02
2024-02-26 11:24:44 iteration: 521000 loss: 0.0019 lr: 0.02
2024-02-26 11:26:17 iteration: 522000 loss: 0.0019 lr: 0.02
2024-02-26 11:27:48 iteration: 523000 loss: 0.0019 lr: 0.02
2024-02-26 11:29:19 iteration: 524000 loss: 0.0019 lr: 0.02
2024-02-26 11:30:51 iteration: 525000 loss: 0.0019 lr: 0.02
2024-02-26 11:32:23 iteration: 526000 loss: 0.0018 lr: 0.02
2024-02-26 11:33:54 iteration: 527000 loss: 0.0019 lr: 0.02
2024-02-26 11:35:24 iteration: 528000 loss: 0.0018 lr: 0.02
2024-02-26 11:36:56 iteration: 529000 loss: 0.0018 lr: 0.02
2024-02-26 11:38:29 iteration: 530000 loss: 0.0018 lr: 0.02
2024-02-26 11:40:02 iteration: 531000 loss: 0.0018 lr: 0.02
2024-02-26 11:41:33 iteration: 532000 loss: 0.0018 lr: 0.02
2024-02-26 11:43:04 iteration: 533000 loss: 0.0018 lr: 0.02
2024-02-26 11:44:37 iteration: 534000 loss: 0.0018 lr: 0.02
2024-02-26 11:46:10 iteration: 535000 loss: 0.0017 lr: 0.02
2024-02-26 11:47:42 iteration: 536000 loss: 0.0018 lr: 0.02
2024-02-26 11:49:15 iteration: 537000 loss: 0.0017 lr: 0.02
2024-02-26 11:50:45 iteration: 538000 loss: 0.0017 lr: 0.02
2024-02-26 11:52:18 iteration: 539000 loss: 0.0018 lr: 0.02
2024-02-26 11:53:50 iteration: 540000 loss: 0.0017 lr: 0.02
2024-02-26 11:55:20 iteration: 541000 loss: 0.0017 lr: 0.02
2024-02-26 11:56:53 iteration: 542000 loss: 0.0017 lr: 0.02
2024-02-26 11:58:23 iteration: 543000 loss: 0.0017 lr: 0.02
2024-02-26 11:59:54 iteration: 544000 loss: 0.0017 lr: 0.02
2024-02-26 12:01:25 iteration: 545000 loss: 0.0016 lr: 0.02
2024-02-26 12:02:57 iteration: 546000 loss: 0.0017 lr: 0.02
2024-02-26 12:04:30 iteration: 547000 loss: 0.0017 lr: 0.02
2024-02-26 12:06:01 iteration: 548000 loss: 0.0017 lr: 0.02
2024-02-26 12:07:32 iteration: 549000 loss: 0.0017 lr: 0.02
2024-02-26 12:09:05 iteration: 550000 loss: 0.0016 lr: 0.02
2024-02-26 12:10:37 iteration: 551000 loss: 0.0017 lr: 0.02
2024-02-26 12:12:08 iteration: 552000 loss: 0.0016 lr: 0.02
2024-02-26 12:13:40 iteration: 553000 loss: 0.0017 lr: 0.02
2024-02-26 12:15:13 iteration: 554000 loss: 0.0017 lr: 0.02
2024-02-26 12:16:46 iteration: 555000 loss: 0.0017 lr: 0.02
2024-02-26 12:18:17 iteration: 556000 loss: 0.0016 lr: 0.02
2024-02-26 12:19:47 iteration: 557000 loss: 0.0016 lr: 0.02
2024-02-26 12:21:18 iteration: 558000 loss: 0.0016 lr: 0.02
2024-02-26 12:22:49 iteration: 559000 loss: 0.0016 lr: 0.02
2024-02-26 12:24:22 iteration: 560000 loss: 0.0016 lr: 0.02
2024-02-26 12:25:52 iteration: 561000 loss: 0.0016 lr: 0.02
2024-02-26 12:27:25 iteration: 562000 loss: 0.0017 lr: 0.02
2024-02-26 12:28:56 iteration: 563000 loss: 0.0016 lr: 0.02
2024-02-26 12:30:28 iteration: 564000 loss: 0.0016 lr: 0.02
2024-02-26 12:32:00 iteration: 565000 loss: 0.0017 lr: 0.02
2024-02-26 12:33:32 iteration: 566000 loss: 0.0017 lr: 0.02
2024-02-26 12:35:02 iteration: 567000 loss: 0.0016 lr: 0.02
2024-02-26 12:36:36 iteration: 568000 loss: 0.0016 lr: 0.02
2024-02-26 12:38:07 iteration: 569000 loss: 0.0016 lr: 0.02
2024-02-26 12:39:38 iteration: 570000 loss: 0.0016 lr: 0.02
2024-02-26 12:41:10 iteration: 571000 loss: 0.0016 lr: 0.02
2024-02-26 12:42:42 iteration: 572000 loss: 0.0016 lr: 0.02
2024-02-26 12:44:13 iteration: 573000 loss: 0.0016 lr: 0.02
2024-02-26 12:45:45 iteration: 574000 loss: 0.0015 lr: 0.02
2024-02-26 12:47:17 iteration: 575000 loss: 0.0016 lr: 0.02
2024-02-26 12:48:49 iteration: 576000 loss: 0.0016 lr: 0.02
2024-02-26 12:50:22 iteration: 577000 loss: 0.0016 lr: 0.02
2024-02-26 12:51:53 iteration: 578000 loss: 0.0015 lr: 0.02
2024-02-26 12:53:28 iteration: 579000 loss: 0.0016 lr: 0.02
2024-02-26 12:54:59 iteration: 580000 loss: 0.0016 lr: 0.02
2024-02-26 12:56:31 iteration: 581000 loss: 0.0015 lr: 0.02
2024-02-26 12:58:03 iteration: 582000 loss: 0.0016 lr: 0.02
2024-02-26 12:59:35 iteration: 583000 loss: 0.0015 lr: 0.02
2024-02-26 13:01:08 iteration: 584000 loss: 0.0015 lr: 0.02
2024-02-26 13:02:38 iteration: 585000 loss: 0.0015 lr: 0.02
2024-02-26 13:04:11 iteration: 586000 loss: 0.0016 lr: 0.02
2024-02-26 13:05:42 iteration: 587000 loss: 0.0015 lr: 0.02
2024-02-26 13:07:13 iteration: 588000 loss: 0.0015 lr: 0.02
2024-02-26 13:08:45 iteration: 589000 loss: 0.0015 lr: 0.02
2024-02-26 13:10:20 iteration: 590000 loss: 0.0015 lr: 0.02
2024-02-26 13:11:53 iteration: 591000 loss: 0.0015 lr: 0.02
2024-02-26 13:13:22 iteration: 592000 loss: 0.0015 lr: 0.02
2024-02-26 13:14:52 iteration: 593000 loss: 0.0015 lr: 0.02
2024-02-26 13:16:24 iteration: 594000 loss: 0.0015 lr: 0.02
2024-02-26 13:17:56 iteration: 595000 loss: 0.0015 lr: 0.02
2024-02-26 13:19:30 iteration: 596000 loss: 0.0015 lr: 0.02
2024-02-26 13:21:00 iteration: 597000 loss: 0.0015 lr: 0.02
2024-02-26 13:22:35 iteration: 598000 loss: 0.0015 lr: 0.02
2024-02-26 13:24:06 iteration: 599000 loss: 0.0015 lr: 0.02
2024-02-26 13:25:39 iteration: 600000 loss: 0.0015 lr: 0.02
2024-02-26 13:27:10 iteration: 601000 loss: 0.0015 lr: 0.02
2024-02-26 13:28:44 iteration: 602000 loss: 0.0015 lr: 0.02
2024-02-26 13:30:15 iteration: 603000 loss: 0.0015 lr: 0.02
2024-02-26 13:31:45 iteration: 604000 loss: 0.0015 lr: 0.02
2024-02-26 13:33:17 iteration: 605000 loss: 0.0015 lr: 0.02
2024-02-26 13:34:48 iteration: 606000 loss: 0.0015 lr: 0.02
2024-02-26 13:36:18 iteration: 607000 loss: 0.0015 lr: 0.02
2024-02-26 13:37:51 iteration: 608000 loss: 0.0015 lr: 0.02
2024-02-26 13:39:22 iteration: 609000 loss: 0.0015 lr: 0.02
2024-02-26 13:40:53 iteration: 610000 loss: 0.0015 lr: 0.02
2024-02-26 13:42:25 iteration: 611000 loss: 0.0015 lr: 0.02
2024-02-26 13:43:58 iteration: 612000 loss: 0.0015 lr: 0.02
2024-02-26 13:45:28 iteration: 613000 loss: 0.0015 lr: 0.02
2024-02-26 13:46:59 iteration: 614000 loss: 0.0015 lr: 0.02
2024-02-26 13:48:31 iteration: 615000 loss: 0.0015 lr: 0.02
2024-02-26 13:50:03 iteration: 616000 loss: 0.0015 lr: 0.02
2024-02-26 13:51:34 iteration: 617000 loss: 0.0015 lr: 0.02
2024-02-26 13:53:06 iteration: 618000 loss: 0.0014 lr: 0.02
2024-02-26 13:54:36 iteration: 619000 loss: 0.0015 lr: 0.02
2024-02-26 13:56:08 iteration: 620000 loss: 0.0014 lr: 0.02
2024-02-26 13:57:39 iteration: 621000 loss: 0.0015 lr: 0.02
2024-02-26 13:59:09 iteration: 622000 loss: 0.0014 lr: 0.02
2024-02-26 14:00:40 iteration: 623000 loss: 0.0014 lr: 0.02
2024-02-26 14:02:12 iteration: 624000 loss: 0.0015 lr: 0.02
2024-02-26 14:03:43 iteration: 625000 loss: 0.0015 lr: 0.02
2024-02-26 14:05:17 iteration: 626000 loss: 0.0015 lr: 0.02
2024-02-26 14:06:50 iteration: 627000 loss: 0.0015 lr: 0.02
2024-02-26 14:08:23 iteration: 628000 loss: 0.0015 lr: 0.02
2024-02-26 14:09:55 iteration: 629000 loss: 0.0015 lr: 0.02
2024-02-26 14:11:27 iteration: 630000 loss: 0.0014 lr: 0.02
2024-02-26 14:12:59 iteration: 631000 loss: 0.0015 lr: 0.02
2024-02-26 14:14:31 iteration: 632000 loss: 0.0015 lr: 0.02
2024-02-26 14:16:02 iteration: 633000 loss: 0.0014 lr: 0.02
2024-02-26 14:17:37 iteration: 634000 loss: 0.0015 lr: 0.02
2024-02-26 14:19:10 iteration: 635000 loss: 0.0015 lr: 0.02
2024-02-26 14:20:41 iteration: 636000 loss: 0.0015 lr: 0.02
2024-02-26 14:22:12 iteration: 637000 loss: 0.0014 lr: 0.02
2024-02-26 14:23:42 iteration: 638000 loss: 0.0014 lr: 0.02
2024-02-26 14:25:14 iteration: 639000 loss: 0.0014 lr: 0.02
2024-02-26 14:26:45 iteration: 640000 loss: 0.0015 lr: 0.02
2024-02-26 14:28:17 iteration: 641000 loss: 0.0014 lr: 0.02
2024-02-26 14:29:48 iteration: 642000 loss: 0.0014 lr: 0.02
2024-02-26 14:31:22 iteration: 643000 loss: 0.0014 lr: 0.02
2024-02-26 14:32:55 iteration: 644000 loss: 0.0014 lr: 0.02
2024-02-26 14:34:27 iteration: 645000 loss: 0.0015 lr: 0.02
2024-02-26 14:36:00 iteration: 646000 loss: 0.0014 lr: 0.02
2024-02-26 14:37:32 iteration: 647000 loss: 0.0015 lr: 0.02
2024-02-26 14:39:05 iteration: 648000 loss: 0.0014 lr: 0.02
2024-02-26 14:40:34 iteration: 649000 loss: 0.0014 lr: 0.02
2024-02-26 14:42:06 iteration: 650000 loss: 0.0015 lr: 0.02
2024-02-26 14:43:39 iteration: 651000 loss: 0.0014 lr: 0.02
2024-02-26 14:45:12 iteration: 652000 loss: 0.0014 lr: 0.02
2024-02-26 14:46:47 iteration: 653000 loss: 0.0014 lr: 0.02
2024-02-26 14:48:20 iteration: 654000 loss: 0.0014 lr: 0.02
2024-02-26 14:49:51 iteration: 655000 loss: 0.0014 lr: 0.02
2024-02-26 14:51:22 iteration: 656000 loss: 0.0014 lr: 0.02
2024-02-26 14:52:54 iteration: 657000 loss: 0.0014 lr: 0.02
2024-02-26 14:54:25 iteration: 658000 loss: 0.0014 lr: 0.02
2024-02-26 14:55:58 iteration: 659000 loss: 0.0014 lr: 0.02
2024-02-26 14:57:29 iteration: 660000 loss: 0.0014 lr: 0.02
2024-02-26 14:59:01 iteration: 661000 loss: 0.0014 lr: 0.02
2024-02-26 15:00:31 iteration: 662000 loss: 0.0014 lr: 0.02
2024-02-26 15:02:03 iteration: 663000 loss: 0.0014 lr: 0.02
2024-02-26 15:03:35 iteration: 664000 loss: 0.0014 lr: 0.02
2024-02-26 15:05:06 iteration: 665000 loss: 0.0014 lr: 0.02
2024-02-26 15:06:38 iteration: 666000 loss: 0.0014 lr: 0.02
2024-02-26 15:08:11 iteration: 667000 loss: 0.0014 lr: 0.02
2024-02-26 15:09:42 iteration: 668000 loss: 0.0014 lr: 0.02
2024-02-26 15:11:13 iteration: 669000 loss: 0.0014 lr: 0.02
2024-02-26 15:12:45 iteration: 670000 loss: 0.0014 lr: 0.02
2024-02-26 15:14:18 iteration: 671000 loss: 0.0014 lr: 0.02
2024-02-26 15:15:50 iteration: 672000 loss: 0.0014 lr: 0.02
2024-02-26 15:17:22 iteration: 673000 loss: 0.0014 lr: 0.02
2024-02-26 15:18:53 iteration: 674000 loss: 0.0014 lr: 0.02
2024-02-26 15:20:24 iteration: 675000 loss: 0.0014 lr: 0.02
2024-02-26 15:21:55 iteration: 676000 loss: 0.0014 lr: 0.02
2024-02-26 15:23:28 iteration: 677000 loss: 0.0014 lr: 0.02
2024-02-26 15:25:00 iteration: 678000 loss: 0.0014 lr: 0.02
2024-02-26 15:26:32 iteration: 679000 loss: 0.0014 lr: 0.02
2024-02-26 15:28:03 iteration: 680000 loss: 0.0014 lr: 0.02
2024-02-26 15:29:35 iteration: 681000 loss: 0.0014 lr: 0.02
2024-02-26 15:31:08 iteration: 682000 loss: 0.0014 lr: 0.02
2024-02-26 15:32:39 iteration: 683000 loss: 0.0014 lr: 0.02
2024-02-26 15:34:11 iteration: 684000 loss: 0.0014 lr: 0.02
2024-02-26 15:35:42 iteration: 685000 loss: 0.0014 lr: 0.02
2024-02-26 15:37:15 iteration: 686000 loss: 0.0014 lr: 0.02
2024-02-26 15:38:47 iteration: 687000 loss: 0.0014 lr: 0.02
2024-02-26 15:40:18 iteration: 688000 loss: 0.0014 lr: 0.02
2024-02-26 15:41:50 iteration: 689000 loss: 0.0014 lr: 0.02
2024-02-26 15:43:22 iteration: 690000 loss: 0.0014 lr: 0.02
2024-02-26 15:44:53 iteration: 691000 loss: 0.0014 lr: 0.02
2024-02-26 15:46:25 iteration: 692000 loss: 0.0014 lr: 0.02
2024-02-26 15:47:57 iteration: 693000 loss: 0.0014 lr: 0.02
2024-02-26 15:49:29 iteration: 694000 loss: 0.0014 lr: 0.02
2024-02-26 15:51:00 iteration: 695000 loss: 0.0014 lr: 0.02
2024-02-26 15:52:31 iteration: 696000 loss: 0.0014 lr: 0.02
2024-02-26 15:54:03 iteration: 697000 loss: 0.0013 lr: 0.02
2024-02-26 15:55:34 iteration: 698000 loss: 0.0014 lr: 0.02
2024-02-26 15:57:06 iteration: 699000 loss: 0.0014 lr: 0.02
2024-02-26 15:58:38 iteration: 700000 loss: 0.0014 lr: 0.02
