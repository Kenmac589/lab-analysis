
@article{Nath2019,
	title = {Using {DeepLabCut} for {3D} markerless pose estimation across species and behaviors},
	volume = {14},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1750-2799},
	url = {https://www.nature.com/articles/s41596-019-0176-0},
	doi = {10.1038/s41596-019-0176-0},
	abstract = {Noninvasive behavioral tracking of animals during experiments is critical to many scientific pursuits. Extracting the poses of animals without using markers is often essential to measuring behavioral effects in biomechanics, genetics, ethology, and neuroscience. However, extracting detailed poses without markers in dynamically changing backgrounds has been challenging. We recently introduced an open-source toolbox called DeepLabCut that builds on a state-of-the-art human pose-estimation algorithm to allow a user to train a deep neural network with limited training data to precisely track user-defined features that match human labeling accuracy. Here, we provide an updated toolbox, developed as a Python package, that includes new features such as graphical user interfaces (GUIs), performance improvements, and active-learning-based network refinement. We provide a step-by-step procedure for using DeepLabCut that guides the user in creating a tailored, reusable analysis pipeline with a graphical processing unit (GPU) in 1{\textendash}12 h (depending on frame size). Additionally, we provide Docker environments and Jupyter Notebooks that can be run on cloud resources such as Google Colaboratory.},
	language = {en},
	number = {7},
	urldate = {2023-12-01},
	journal = {Nature Protocols},
	author = {Nath, Tanmay and Mathis, Alexander and Chen, An Chi and Patel, Amir and Bethge, Matthias and Mathis, Mackenzie Weygandt},
	month = jul,
	year = {2019},
	note = {Number: 7
Publisher: Nature Publishing Group},
	keywords = {??, Behavioural methods, Computational platforms and environments, Learning algorithms, Software},
	pages = {2152--2176},
	file = {Nath2019.pdf:/Users/kenzie_mackinnon/Documents/papers/grad_school/Nath2019.pdf:application/pdf},
}
