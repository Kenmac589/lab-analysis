@comment{x-kbibtex-encoding=utf-8}

@article{Klein_2022,
	abstract = {Automatization and technological advances have led to a larger number of methods and systems to monitor and measure locomotor activity and more specific behavior of a wide variety of animal species in various environmental conditions in laboratory settings. In rodents, the majority of these systems require the animals to be temporarily taken away from their home-cage into separate observation cage environments which requires manual handling and consequently evokes distress for the animal and may alter behavioral responses. An automated high-throughput approach can overcome this problem. Therefore, this review describes existing automated methods and technologies which enable the measurement of locomotor activity and behavioral aspects of rodents in their most meaningful and stress-free laboratory environment: the home-cage. In line with the Directive 2010/63/EU and the 3R principles (replacement, reduction, refinement), this review furthermore assesses their suitability and potential for group-housed conditions as a refinement strategy, highlighting their current technological and practical limitations. It covers electrical capacitance technology and radio-frequency identification (RFID), which focus mainly on voluntary locomotor activity in both single and multiple rodents, respectively. Infrared beams and force plates expand the detection beyond locomotor activity toward basic behavioral traits but discover their full potential in individually housed rodents only. Despite the great premises of these approaches in terms of behavioral pattern recognition, more sophisticated methods, such as (RFID-assisted) video tracking technology need to be applied to enable the automated analysis of advanced behavioral aspects of individual animals in social housing conditions.},
	author = {Christian J. M. I. Klein and Christian J M I Klein and Thomas Budiman and Thomas Budiman and Judith R. Homberg and Judith R Homberg and Dilip Verma and Dilip Verma and Jaap Keijer and Jaap Keijer and Evert M. van Schothorst and Evert M van Schothorst},
	doi = {10.3389/fnbeh.2022.877323},
	journal = {Frontiers in Behavioral Neuroscience},
	localfile = {Klein_2022.pdf},
	mag_id = {4226109930},
	pmcid = {null},
	pmid = {35464142},
	title = {Measuring Locomotor Activity and Behavioral Aspects of Rodents Living in the Home-Cage},
	year = {2022}
}

@article{Zhang_2022,
	abstract = {Optogenetics and calcium imaging can be combined to simultaneously stimulate and record neural activity in vivo. However, this usually requires two-photon microscopes, which are not portable nor affordable. Here we report the design and implementation of a miniaturized one-photon endoscope for performing simultaneous optogenetic stimulation and calcium imaging. By integrating digital micromirrors, the endoscope makes it possible to activate any neuron of choice within the field of view, and to apply arbitrary spatiotemporal patterns of photostimulation while imaging calcium activity. We used the endoscope to image striatal neurons from either the direct pathway or the indirect pathway in freely moving mice while activating any chosen neuron in the field of view. The endoscope also allows for the selection of neurons based on their relationship with specific animal behaviour, and to recreate the behaviour by mimicking the natural neural activity with photostimulation. The miniaturized endoscope may facilitate the study of how neural activity gives rise to behaviour in freely moving animals.},
	author = {Jinyong Zhang and Jinyong Zhang and Ryan N. Hughes and Ryan N. Hughes and Namsoo Kim and Namsoo Kim and Isabella P. Fallon and Isabella P. Fallon and Konstantin Bakhurin and Konstantin I. Bakhurin and Jiwon Kim and Jiwon Kim and Francesco Paolo Ulloa Severino and Francesco Paolo Ulloa Severino and Henry H. Yin and Henry H. Yin},
	doi = {10.1038/s41551-022-00920-3},
	journal = {Nature Biomedical Engineering},
	mag_id = {4291624870},
	pmcid = {null},
	pmid = {35970930},
	title = {A one-photon endoscope for simultaneous patterned optogenetic stimulation and calcium imaging in freely behaving mice},
	year = {2022}
}

@article{Newman_2023,
	abstract = {Behavioral neuroscience faces two conflicting demands: long-duration recordings from large neural populations and unimpeded animal behavior. To meet this challenge, we developed ONIX, an open-source data acquisition system with high data throughput (2GB/sec) and low closed-loop latencies (\&lt;1ms) that uses a novel 0.3 mm thin tether to minimize behavioral impact. Head position and rotation are tracked in 3D and used to drive active commutation without torque measurements. ONIX can acquire from combinations of passive electrodes, Neuropixels probes, head-mounted microscopes, cameras, 3D-trackers, and other data sources. We used ONIX to perform uninterrupted, long (∼7 hours) neural recordings in mice as they traversed complex 3-dimensional terrain. ONIX allowed exploration with similar mobility as non-implanted animals, in contrast to conventional tethered systems which restricted movement. By combining long recordings with full mobility, our technology will enable new progress on questions that require high-quality neural recordings during ethologically grounded behaviors.},
	author = {Jonathan P. Newman and Jie Zhang and Aarón Cuevas-López and Nicholas J. Miller and Takato Honda and Marie-Sophie H van der Goes and Alexandra H Leighton and Filipe Carvalho and Gonçalo Lopes and Anna A Lakunina and Joshua H. Siegle and Mark T. Harnett and Matthew A. Wilson and Jakob Voigts},
	doi = {10.1101/2023.08.30.554672},
	journal = {null},
	mag_id = {4386351696},
	pmcid = {null},
	pmid = {37693443},
	title = {A unified open-source platform for multimodal neural recording and perturbation during naturalistic behavior},
	year = {2023}
}

@article{Li_2023,
	abstract = {ABSTRACT Skilled motor behaviors require orderly coordination of multiple constituent movements with sensory cues towards achieving a goal, but the underlying brain circuit mechanisms remain unclear. Here we show that target-guided reach-grasp-to-drink (RGD) in mice involves the ordering and coordination of a set of forelimb and oral actions. Cortex-wide activity imaging of multiple glutamatergic projection neuron (PN) types uncovered a network, involving the secondary motor cortex (MOs), forelimb primary motor and somatosensory cortex, that tracked RGD movements. Photo-inhibition highlighted MOs in coordinating RGD movements. Within the MOs, population neural trajectories tracked RGD progression and single neuron activities integrated across constituent movements. Notably, MOs intratelencephalic, pyramidal tract, and corticothalamic PN activities correlated with action coordination, showed distinct neural dynamics trajectories, and differentially contributed to movement coordination. Our results delineate a cortical network and key areas, PN types, and neural dynamics therein that articulate the serial order and coordination of a skilled behavior.},
	author = {Yi Li and Xu An and Yongjun Qian and Xinmeng Xu and Shengli Zhao and Hemanth Mohan and Ludovica Bachschmid-Romano and Nicolas Brunel and Ian Q. Whishaw and Z. Josh Huang},
	doi = {10.1101/2023.10.25.563871},
	journal = {null},
	mag_id = {4388191255},
	pmcid = {null},
	pmid = {37961483},
	title = {Cortical network and projection neuron types that articulate serial order in a skilled motor behavior},
	year = {2023}
}

@article{Yamanouchi_2023,
	abstract = {Manipulation of neural activity is necessary for identifying the neural basis of animal behavior. Optogenetic methods allow time-specific manipulation of neural activity in animals with high precision. Devices have been proposed for optogenetics experiments that automatically detect animal behavior and trigger photostimulations, but it is difficult for biologists to implement these devices in an experimental system because of the complicated system and programming. In this study, we establish an event-triggered feedback system for optogenetic manipulation of neural activity that is introduced in the experimental system easily and highly applicable. Using fly copulation as an example, we evaluated the models for fly copulation detections and succeeded in detecting copulation initiation with high accuracy.},
	author = {Hayato M. Yamanouchi and Ryoya Tanaka and Azusa Kamikouchi},
	doi = {10.1109/percomworkshops56833.2023.10150245},
	journal = {null},
	localfile = {Yamanouchi_2023.pdf},
	mag_id = {4381746847},
	pmcid = {null},
	pmid = {null},
	title = {Event-triggered feedback system using YOLO for optogenetic manipulation of neural activity},
	year = {2023}
}

@article{Luxem_2023,
	abstract = {Recently developed methods for video analysis, especially models for pose estimation and behavior classification, are transforming behavioral quantification to be more precise, scalable, and reproducible in fields such as neuroscience and ethology. These tools overcome long-standing limitations of manual scoring of video frames and traditional ‘center of mass’ tracking algorithms to enable video analysis at scale. The expansion of open-source tools for video acquisition and analysis has led to new experimental approaches to understand behavior. Here, we review currently available open-source tools for video analysis and discuss how to set up these methods for labs new to video recording. We also discuss best practices for developing and using video analysis methods, including community-wide standards and critical needs for the open sharing of datasets and code, more widespread comparisons of video analysis methods, and better documentation for these methods especially for new users. We encourage broader adoption and continued development of these tools, which have tremendous potential for accelerating scientific progress in understanding the brain and behavior.},
	author = {Kevin Luxem and Jennifer J. Sun and Sean P Bradley and Keerthi Krishnan and Eric A. Yttri and Jan Zimmermann and Talmo Pereira and Mark Laubach},
	doi = {10.7554/elife.79305},
	journal = {null},
	localfile = {Luxem_2023.pdf},
	mag_id = {4353074833},
	pmcid = {null},
	pmid = {36951911},
	title = {Open-source tools for behavioral video analysis: Setup, methods, and best practices},
	year = {2023}
}

@article{Terstege_2023,
	abstract = {Fiber photometry offers insight into cell-type-specific activity underlying social interactions. We provide a protocol for the integration of fiber photometry recordings into the analysis of social behavior in rodent models. This includes considerations during surgery, notes on synchronizing fiber photometry with behavioral recordings, advice on using multi-animal behavioral tracking software, and scripts for the analysis of fiber photometry recordings. For complete details on the use and execution of this protocol, please refer to Dawson et al. (2023).1},
	author = {Dylan J Terstege and Matthew Dawson and Naila Jamani and Mio Tsutsui and Jonathan R. Epp and Derya Sargin},
	doi = {10.1016/j.xpro.2023.102689},
	journal = {null},
	localfile = {Terstege_2023.pdf},
	mag_id = {4388795990},
	pmcid = {null},
	pmid = {37979176},
	title = {Protocol for the integration of fiber photometry and social behavior in rodent models},
	year = {2023}
}

@article{Omainska_2023,
	abstract = {We address in this letter the learning of unknown rigid body motions in the Special Euclidian Group SE(3) based on Gaussian Processes. A new covariance kernel for SE(3) is presented and proven to be a valid kernel for Gaussian Process Regression. The learning error of the proposed Gaussian Process model is extended to a highprobability statement on SE(3). We employ it in a visual pursuit scenario of a moving target with unknown velocity in 3D space. Our approach is validated in a simulated 3D environment in Unity, and shows significant better prediction accuracy than the most commonly used Gaussian kernel. When compared to other covariance kernels proposed on SE(3), its advantages are a natural extension of covering numbers to SE(3), that it is computationally more efficient, and that stability of target pursuit can be guaranteed without limiting the target rotational space to SO(2).},
	author = {Marco Omainska and Junya Yamauchi and Armin Lederer and Sandra Hirche and Masayuki Fujita},
	doi = {10.1109/lcsys.2023.3287507},
	journal = {null},
	mag_id = {4381163328},
	pmcid = {null},
	pmid = {null},
	title = {Rigid Motion Gaussian Processes with SE(3) Kernel and Application to Visual Pursuit Control},
	year = {2023}
}

@article{Brockway_2023,
	abstract = {We sought to characterize the unique role of somatostatin (SST) in the prelimbic (PL) cortex in mice. We performed slice electrophysiology in pyramidal and GABAergic neurons to characterize the pharmacological mechanism of SST signaling and fiber photometry of GCaMP6f fluorescent calcium signals from SST neurons to characterize the activity profile of SST neurons during exploration of an elevated plus maze (EPM) and open field test (OFT). We used local delivery of a broad SST receptor (SSTR) agonist and antagonist to test causal effects of SST signaling. SSTR activation hyperpolarizes layer 2/3 pyramidal neurons, an effect that is recapitulated with optogenetic stimulation of SST neurons. SST neurons in PL are activated during EPM and OFT exploration, and SSTR agonist administration directly into the PL enhances open arm exploration in the EPM. This work describes a broad ability for SST peptide signaling to modulate microcircuits within the prefrontal cortex and related exploratory behaviors.},
	author = {Dakota F. Brockway and Keith R. Griffith and Chloe Aloimonos and Thomas Clarity and J. Brody Moyer and Grace C Smith and Nigel C. Dao and Md. Shakhawat Hossain and Patrick J. Drew and Joshua A. Gordon and David A. Kupferschmidt and Nicole A. Crowley},
	doi = {10.1016/j.celrep.2023.112976},
	journal = {null},
	mag_id = {4385969373},
	pmcid = {null},
	pmid = {37590138},
	title = {Somatostatin peptide signaling dampens cortical circuits and promotes exploratory behavior},
	year = {2023}
}

@article{Hooren_2023,
	abstract = {Abstract Background Markerless motion capture based on low‐cost 2‐D video analysis in combination with computer vision techniques has the potential to provide accurate analysis of running technique in both a research and clinical setting. However, the accuracy of markerless motion capture for assessing running kinematics compared to a gold‐standard approach remains largely unexplored. Objective Here, we investigate the accuracy of custom‐trained (DeepLabCut) and existing (OpenPose) computer vision techniques for assessing sagittal‐plane hip, knee, and ankle running kinematics at speeds of 2.78 and 3.33 m s −1 as compared to gold‐standard marker‐based motion capture. Methods Differences between the markerless and marker‐based approaches were assessed using statistical parameter mapping and expressed as root mean squared errors (RMSEs). Results After temporal alignment and offset removal, both DeepLabCut and OpenPose showed no significant differences with the marker‐based approach at 2.78 m s −1 , but some significant differences remained at 3.33 m s −1 . At 2.78 m s −1 , RMSEs were 5.07, 7.91, and 5.60, and 5.92, 7.81, and 5.66 degrees for the hip, knee, and ankle for DeepLabCut and OpenPose, respectively. At 3.33 m s −1 , RMSEs were 7.40, 10.9, 8.01, and 4.95, 7.45, and 5.76 for the hip, knee, and ankle for DeepLabCut and OpenPose, respectively. Conclusion The differences between OpenPose and the marker‐based method were in line with or smaller than reported between other kinematic analysis methods and marker‐based methods, while these differences were larger for DeepLabCut. Since the accuracy differed between individuals, OpenPose may be most useful to facilitate large‐scale in‐field data collection and investigation of group effects rather than individual‐level analyses.},
	author = {Bas Van Hooren and Noah Pecasse and K. Meijer and J M N Hans Essers},
	doi = {10.1111/sms.14319},
	journal = {null},
	mag_id = {4317651232},
	pmcid = {null},
	pmid = {36680411},
	title = {The accuracy of markerless motion capture combined with computer vision techniques for measuring running kinematics},
	year = {2023}
}

@article{Saha_2023,
	abstract = {This article presents a highly scalable and rack-mountable wireless sensing system for long-term monitoring (i.e., sense and estimate) of small animal/s' physical state (SAPS), such as changes in location and posture within standard cages. The conventional tracking systems may lack one or more features such as scalability, cost efficiency, rack-mount ability, and light condition insensitivity to work 24/7 on a large scale. The proposed sensing mechanism relies on relative changes of multiple resonance frequencies due to the animal's presence over the sensor unit. The sensor unit can track SAPS changes based on changes in electrical properties in the sensors near fields, appearing in the resonance frequencies, i.e., an Electromagnetic (EM) Signature, within the 200 MHz–300 MHz frequency range. The sensing unit is located underneath a standard mouse cage and consists of thin layers of a reading coil and six resonators tuned at six distinct frequencies. ANSYS HFSS software is used to model and optimize the proposed sensor unit and calculate the Specific Absorption Rate (SAR) obtained under 0.05 W/kg. Multiple prototypes have been implemented to test, validate, and characterize the performance of the design by conducting in vitro and in vivo experiments on Mice. The in-vitro test results have shown a 15 mm spatial resolution in detecting the mouse's location over the sensor array having maximum frequency shifts of 832 kHz and posture detection with under 30° resolution. The in-vivo experiment on mouse displacement resulted in frequency shifts of up to 790 kHz, indicating the SAPS's capability to detect the Mice's physical state.},
	author = {Reepa Saha and Le Jiang and Hoda Salsabili and Miad Faezipour and Sarah Ostadabbas and Benjamin M. Larimer and S. Abdollah Mirbozorgi},
	doi = {10.1109/tbcas.2023.3284823},
	journal = {null},
	mag_id = {4380303524},
	pmcid = {null},
	pmid = {37307182},
	title = {Toward a Smart Sensing System to Monitor Small Animal's Physical State via Multi-Frequency Resonator Array},
	year = {2023}
}

@article{Lauer_2023,
	abstract = {Understanding the mechanical demands of an exercise on the musculoskeletal system is crucial to prescribe effective training or therapeutic interventions. Yet, that knowledge is currently limited in water, mostly because of the difficulty in evaluating external resistance. Here I reconcile recent advances in 3D markerless pose and mesh estimation, biomechanical simulations, and hydrodynamic modeling, to predict lower limb mechanical loading during aquatic exercises. Simulations are driven exclusively from a single video. Fluid forces were estimated within 12.5\ensuremath{\pm}4.1\% of the peak forces determined through computational fluid dynamics analyses, at a speed three orders of magnitude greater. In silico hip and knee resultant joint forces agreed reasonably well with in vivo instrumented implant recordings (R2=0.74) downloaded from the OrthoLoad database, both in magnitude (RMSE =251\ensuremath{\pm}125 N) and direction (cosine similarity = 0.92\ensuremath{\pm}0.09). Hip flexors, glutes, adductors, and hamstrings were the main contributors to hip joint compressive forces (40.4\ensuremath{\pm}12.7\%, 25.6\ensuremath{\pm}9.7\%, 14.2\ensuremath{\pm}4.8\%, 13.0\ensuremath{\pm}8.2\%, respectively), while knee compressive forces were mostly produced by the gastrocnemius (39.1\ensuremath{\pm}15.9\%) and vasti (29.4\ensuremath{\pm}13.7\%). Unlike dry-land locomotion, non-hip- and non-knee-spanning muscles provided little to no offloading effect via dynamic coupling. This noninvasive method has the potential to standardize the reporting of exercise intensity, inform the design of rehabilitation protocols and improve their reproducibility.},
	author = {Jessy Lauer},
	doi = {10.1016/j.jbiomech.2023.111576},
	journal = {null},
	mag_id = {4362608169},
	pmcid = {null},
	pmid = {37043928},
	title = {Video-driven simulation of lower limb mechanical loading during aquatic exercises},
	year = {2023}
}

@article{Monsees_2022,
	abstract = {Abstract Forming a complete picture of the relationship between neural activity and skeletal kinematics requires quantification of skeletal joint biomechanics during free behavior; however, without detailed knowledge of the underlying skeletal motion, inferring limb kinematics using surface-tracking approaches is difficult, especially for animals where the relationship between the surface and underlying skeleton changes during motion. Here we developed a videography-based method enabling detailed three-dimensional kinematic quantification of an anatomically defined skeleton in untethered freely behaving rats and mice. This skeleton-based model was constrained using anatomical principles and joint motion limits and provided skeletal pose estimates for a range of body sizes, even when limbs were occluded. Model-inferred limb positions and joint kinematics during gait and gap-crossing behaviors were verified by direct measurement of either limb placement or limb kinematics using inertial measurement units. Together we show that complex decision-making behaviors can be accurately reconstructed at the level of skeletal kinematics using our anatomically constrained model.},
	author = {Arne Monsees and Arne Monsees and Kay-Michael Voit and Kay-Michael Voit and Damian J. Wallace and Damian J. Wallace and Juergen Sawinski and J Sawiński and Edyta Charyasz and Edyta Charyasz and Klaus Scheffler and Klaus Scheffler and Jakob H. Macke and Jakob H. Macke and Jason N. D. Kerr and Jason N. D. Kerr},
	doi = {10.1038/s41592-022-01634-9},
	journal = {Nature Methods},
	localfile = {Monsees_2022.pdf},
	mag_id = {4306411987},
	pmcid = {null},
	pmid = {36253644},
	title = {Estimation of skeletal kinematics in freely moving rodents},
	year = {2022}
}

@article{Wang_2022,
	abstract = {Multiscale neurophysiology reveals that simple motor actions are associated with changes in neuronal firing in virtually every brain region studied. Accordingly, the assessment of focal pathology such as stroke or progressive neurodegenerative diseases must also extend widely across brain areas. To derive mechanistic information through imaging, multiple resolution scales and multimodal factors must be included, such as the structure and function of specific neurons and glial cells and the dynamics of specific neurotransmitters. Emerging multiscale methods in preclinical animal studies that span micro- to macroscale examinations fill this gap, allowing a circuit-based understanding of pathophysiological mechanisms. Combined with high-performance computation and open-source data repositories, these emerging multiscale and large field-of-view techniques include live functional ultrasound, multi- and single-photon wide-scale light microscopy, video-based miniscopes, and tissue-penetrating fiber photometry, as well as variants of post-mortem expansion microscopy. We present these technologies and outline use cases and data pipelines to uncover new knowledge within animal models of stroke, Alzheimer's disease, and movement disorders.},
	author = {Yundi Wang and Yundi Wang and Jeffrey M. LeDue and Jeffrey LeDue and Timothy H Murphy and Timothy H. Murphy},
	doi = {10.1016/j.neuron.2022.09.006},
	journal = {Neuron},
	mag_id = {4301395966},
	pmcid = {null},
	pmid = {36198319},
	title = {Multiscale imaging informs translational mouse modeling of neurological disease},
	year = {2022}
}

@article{Lauer_2022,
	abstract = {Understanding the mechanical demands of an exercise on the musculoskeletal system is crucial to prescribe effective training or therapeutic interventions. Yet, that knowledge is currently limited in water, mostly because of the difficulty in evaluating external resistance. Here I reconcile recent advances in 3D markerless pose and mesh estimation, biomechanical simulations, and hydrodynamic modeling, to predict lower limb mechanical loading during aquatic exercises. Simulations are driven exclusively from a single video. In silico hip and knee joint forces agreed well with in vivo instrumented implant recordings downloaded from the OrthoLoad database, both in magnitude and direction. New insights into individual muscle contributions to joint loading were gained. This noninvasive method has the potential to standardize the reporting of exercise intensity, inform the design of rehabilitation protocols and improve their reproducibility.},
	author = {Jessy Lauer and Jessy Lauer},
	doi = {10.1101/2022.11.23.517406},
	journal = {Cold Spring Harbor Laboratory - bioRxiv},
	mag_id = {4310967228},
	pmcid = {null},
	pmid = {null},
	title = {Video-driven simulation of lower limb mechanical loading during aquatic exercises},
	year = {2022}
}

