{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kenzie's DeepLabCut Workflow with Jupyter\n",
    "\n",
    "The goal of this is notebook is to bring together the general guidance on using DeepLab cut, while making the analysis executable in context with the direction.  The first step will be to activate the relevant `conda` environment, which contains DeepLabCut. In the case of the GPU computer, this will be done by launching the *anaconda prompt (anaconda powershell prompt is also fine)* in administator mode and typing `conda activate dlc-windowsGPU-2023'`  While there are other 'conda' environments, this is the most up to date.\n",
    "\n",
    "## General Overview\n",
    "\n",
    "1. Import relevant packages and create project\n",
    "2. Extract frames from imported videos\n",
    "3. Label frames from videos to denote anatomincal landmarks\n",
    "4. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 02:52:13.846035: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-26 02:52:15.882576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-26 02:52:15.882625: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-10-26 02:52:16.123814: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-26 02:52:27.994407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-26 02:52:28.000836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-26 02:52:28.000935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenzie_mackinnon/mambaforge/envs/dlc/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %% Imports\n",
    "import os\n",
    "import platform\n",
    "from datetime import datetime\n",
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the functions that I will be using\n",
    "\n",
    "# Lists all files in a directory\n",
    "def filePathList(dir_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "# Converts file paths in between Unix and DOS\n",
    "def pathconvUnixToDos(paths):\n",
    "    dos_paths = []\n",
    "    for path in paths:\n",
    "        dos_path = path.replace('/', '\\\\')\n",
    "        dos_path = \"C:\" + dos_path\n",
    "        dos_paths.append(dos_path)\n",
    "    return dos_paths\n",
    "\n",
    "# Checks to see if a directory is already present\n",
    "def directoryPresent(targetPath, projName):\n",
    "    path = os.path.join(projName, targetPath)\n",
    "\n",
    "    # Will return boolean\n",
    "    return os.path.isdir(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to do is give two paths, which are where we want to put the project `targetForProject` and where are the videos we want to import currently stored `videoImportPath`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering User input\n",
    "projectName = str(input(\"Enter a project name: \"))\n",
    "experimenterName = str(input(\"Enter name of experimenter: \"))\n",
    "targetForProject = str(input(\"Give path of parent folder you would like to place project in: \"))\n",
    "videoImportPath = str(input(\"Enter file path for videos you want to import: \"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take the paths given and put together the command that has to be done to create a new project.  It will also account for the operating system used at the time and adjust the list of video file paths accordingly making this work on whatever system is being used.  Furthermore, to prevent overwriting a project that might already exist in the place where you want to put the project, there is also a check to make sure that the new project is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the OS processing the file we will run different functions to create file path lists\n",
    "operatingSystem = platform.system()\n",
    "\n",
    "if operatingSystem == \"Windows\":\n",
    "    print(\"Window operating system detected!\")\n",
    "\n",
    "    # Path where recorded videos can currently be found\n",
    "    videoImportPath = str(input(\"Enter file path for videos you want to import: \"))\n",
    "\n",
    "    # Creating list of file paths for each video in specified folder\n",
    "    file_paths = filePathList(videoImportPath)\n",
    "\n",
    "    # Changing file paths from Unix format to DOS for videos\n",
    "    dos_path_conversion = pathconvUnixToDos(file_paths)\n",
    "    file_paths = dos_path_conversion\n",
    "\n",
    "    # Changing file paths from Unix format to DOS for target directory\n",
    "    # unixPathComponents = targetForProject.split('/')\n",
    "    # targetForProject = os.path.join(*unixPathComponents).replace('/', os.sep)\n",
    "    # print(targetForProject)\n",
    "elif operatingSystem == \"Linux\":\n",
    "    print(\"Linux operating system detected!\")\n",
    "    # Path where recorded videos can currently be found\n",
    "    videoImportPath = str(input(\"Enter file path for videos you want to import: \"))\n",
    "\n",
    "    # Creating list of file paths for each video in specified folder\n",
    "    file_paths = filePathList(videoImportPath)\n",
    "elif operatingSystem == \"Darwin\":\n",
    "    print(\"Darwin(MacOS) operating system detected!\")\n",
    "    # Path where recorded videos can currently be found\n",
    "    videoImportPath = str(input(\"Enter file path for videos you want to import: \"))\n",
    "\n",
    "    # Creating list of file paths for each video in specified folder\n",
    "    file_paths = filePathList(videoImportPath)\n",
    "else:\n",
    "    print(\"Operating system not detected!\")\n",
    "    print(\"Falling back onto Unix path protocol\")\n",
    "    # Path where recorded videos can currently be found\n",
    "    videoImportPath = str(input(\"Enter file path for videos you want to import: \"))\n",
    "\n",
    "    # Creating list of file paths for each video in specified folder\n",
    "    file_paths = filePathList(videoImportPath)\n",
    "\n",
    "# Checking result of variable file path importing\n",
    "print(\"Project Name: \" + projectName)\n",
    "print(\"Experimenter: \" + experimenterName)\n",
    "print(\"Output of file paths:\")\n",
    "print(\"--------------------\")\n",
    "print(file_paths)\n",
    "# %% Creation of project\n",
    "\n",
    "# Checking to see if project with same name alredy exists\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "newProjectName = projectName + \"-\" + experimenterName + \"-\" + current_date\n",
    "\n",
    "if directoryPresent(newProjectName, targetForProject):\n",
    "    print(f\"Directory {newProjectName} already exists in {targetForProject}.\")\n",
    "else:\n",
    "    print(f\"Directory {newProjectName} does not exist in {targetForProject}.\")\n",
    "    config_path = deeplabcut.create_new_project(projectName, experimenterName, file_paths, working_directory=(targetForProject), copy_videos=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Before running next command, make sure `config.yaml` has the appropriate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Extract frames from videos\n",
    "deeplabcut.extract_frames(config_path, mode='automatic', userfeedback=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Label frames\n",
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Check Annotated Frames\n",
    "deeplabcut.check_labels(config_path, visualizeindividuals=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training of Feature Detectors\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. The user can set various parameters in the project `config.yaml`\n",
    "\n",
    "Training can be stopped at any time. Note that the weights are only stored every 'save_iters' steps. For this demo the state it is advisable to store & display the progress very often. In practice this is inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(path_config_file, shuffle=1, displayiters=10, saveiters=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note, that if it reaches the end or you stop it (by hitting \"stop\" or by CTRL+C), you will see an \"KeyboardInterrupt\" error, but you can ignore this!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a trained network\n",
    "\n",
    "This function evaluates a trained model for a specific shuffle/shuffles at a particular training state (snapshot) or on all the states. The network is evaluated on the data set (images) and stores the results as .csv file in a subdirectory under **evaluation-results**.\n",
    "\n",
    "You can change various parameters in the ```config.yaml``` file of this project. For evaluation all the model descriptors (Task, TrainingFraction, Date etc.) are important. For the evaluation one can change pcutoff. This cutoff also influences how likely estimated positions need to be so that they are shown in the plots. One can furthermore, change the colormap and dotsize for those graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(path_config_file,plotting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: depending on your set up sometimes you get some \"matplotlib errors, but these are not important*\n",
    "\n",
    "Now you can go check out the images. Given the limited data input and it took ~20 mins to test this out, it is not meant to track well, so don't be alarmed. This is just to get you familiar with the workflow... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing videos\n",
    "This function extracts the pose based on a trained network from videos. The user can choose the trained network - by default the most recent snapshot is used to analyse the videos. However, the user can also specify the snapshot index for the variable **snapshotindex** in the **config.yaml** file).\n",
    "\n",
    "The results are stored in hd5 file in the same directory, where the video resides. The pose array (pose vs. frame index) can also be exported as csv file (set flag to...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating video path:\n",
    "videofile_path = ('/Users/kenzie_mackinnon/deeplabcut/projects/mac-perturbation_treadmill-kenzie-2023-02-08/videos/m3v1mp4.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start analyzing the video!\")\n",
    "#our demo video on a CPU with take ~30 min to analze! GPU is much faster!\n",
    "deeplabcut.analyze_videos(path_config_file,[videofile_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labeled video\n",
    "\n",
    "This function is for the visualization purpose and can be used to create a video in .mp4 format with the predicted labels. This video is saved in the same directory, where the (unlabeled) video resides. \n",
    "\n",
    "Various parameters can be set with regard to the colormap and the dotsize. The parameters of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,[videofile_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color. The underlying functions can easily be customized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "deeplabcut.plot_trajectories(path_config_file,[videofile_path],showfigures=True)\n",
    "\n",
    "#These plots can are interactive and can be customized (see https://matplotlib.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract outlier frames, where the predictions are off.\n",
    "\n",
    "This is optional step allows to add more training data when the evaluation results are poor. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,[videofile_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can run this iteratively, and (even) extract additional frames from the same video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually correct labels\n",
    "\n",
    "This step allows the user to correct the labels in the extracted frames. Navigate to the folder corresponding to the video 'm3v1mp4' and use the GUI as described in the protocol to update the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perhaps plot the labels to see how how all the frames are annotated (including the refined ones)\n",
    "deeplabcut.check_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge datasets (once you refined all frames)\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new iteration of training dataset, check it and train...\n",
    "\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one can train the network again... (with the expanded data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(path_config_file, shuffle=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcm1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9565301901e75327fdc7fb6f564cf4ec01f7a567182f2fdf4865a4f02c22ee08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
